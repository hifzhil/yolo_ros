#!/usr/bin/env python3
import cv2
import json
import random
import numpy as np
from typing import Tuple

import rclpy
from rclpy.duration import Duration
from rclpy.qos import QoSProfile
from rclpy.qos import QoSHistoryPolicy
from rclpy.qos import QoSDurabilityPolicy
from rclpy.qos import QoSReliabilityPolicy
from rclpy.lifecycle import LifecycleNode
from rclpy.lifecycle import TransitionCallbackReturn
from rclpy.lifecycle import LifecycleState

import message_filters
from cv_bridge import CvBridge
from ultralytics.utils.plotting import Annotator, colors

from sensor_msgs.msg import Image
from std_msgs.msg import String
from visualization_msgs.msg import Marker
from visualization_msgs.msg import MarkerArray
from yolo_msgs.msg import BoundingBox2D
from yolo_msgs.msg import KeyPoint2D
from yolo_msgs.msg import KeyPoint3D
from yolo_msgs.msg import Detection
from yolo_msgs.msg import DetectionArray
from yolo_msgs.msg import ObjectCount, ObjectCounts


class ObjectCounter:
    def __init__(self):
        self.detection_lines = [
            [5, 150, 955, 150],
            [5, 350, 955, 350],
            [150, 5, 150, 535],
            [830, 5, 830, 535]
        ]
        self.line_colors = [(0, 255, 255) for _ in self.detection_lines]
        self.color_change_times = [None for _ in self.detection_lines]
        self.color_duration = 1.0
        self._previous_positions = {}
        self._counted_objects = {}
        self._class_counts = {}
        self.MAX_TRACKED_IDS = 1000

    def cleanup_if_needed(self):
        if len(self._counted_objects) > self.MAX_TRACKED_IDS:
            sorted_tracks = sorted(
                self._counted_objects.items(),
                key=lambda x: x[1],
                reverse=True
            )[:self.MAX_TRACKED_IDS]
            self._counted_objects = dict(sorted_tracks)

    def check_line_crossings(self, detection: Detection, current_time: float) -> bool:
        track_id = detection.id
        if not track_id:
            return False
            
        if track_id in self._counted_objects:
            self._counted_objects[track_id] = current_time
            return False
            
        current_x = detection.bbox.center.position.x
        current_y = detection.bbox.center.position.y
        
        if track_id not in self._previous_positions:
            self._previous_positions[track_id] = (current_x, current_y)
            return False
            
        previous_x, previous_y = self._previous_positions[track_id]
        self._previous_positions[track_id] = (current_x, current_y)
        
        crossed_any = False
        for i, line in enumerate(self.detection_lines):
            if i < 2:
                line_y = line[1]
                if (previous_y <= line_y and current_y > line_y) or \
                   (previous_y >= line_y and current_y < line_y):
                    self.line_colors[i] = (0, 255, 0)
                    self.color_change_times[i] = current_time
                    crossed_any = True
            else:
                line_x = line[0]
                if (previous_x <= line_x and current_x > line_x) or \
                   (previous_x >= line_x and current_x < line_x):
                    self.line_colors[i] = (0, 255, 0)
                    self.color_change_times[i] = current_time
                    crossed_any = True
        
        if crossed_any:
            self._counted_objects[track_id] = current_time
            if detection.class_name not in self._class_counts:
                self._class_counts[detection.class_name] = 0
            self._class_counts[detection.class_name] += 1
            del self._previous_positions[track_id]
            self.cleanup_if_needed()
            
        return crossed_any

    def update_line_colors(self, current_time: float):
        for i, change_time in enumerate(self.color_change_times):
            if change_time is not None:
                if (current_time - change_time) > self.color_duration:
                    self.line_colors[i] = (0, 255, 255)
                    self.color_change_times[i] = None

    def get_counts(self):
        return self._class_counts.copy()

    def draw_lines(self, image: np.ndarray) -> np.ndarray:
        for i, line in enumerate(self.detection_lines):
            cv2.line(image, 
                    (line[0], line[1]),
                    (line[2], line[3]),
                    self.line_colors[i], 
                    2)
        return image


class DebugNode(LifecycleNode):
    def __init__(self) -> None:
        super().__init__("debug_node")
        self.cv_bridge = CvBridge()
        self._class_to_color = {}
        self.object_counter = ObjectCounter()
        self.target_width = 960
        self.target_height = 540

    def on_configure(self, state: State) -> TransitionCallbackReturn:
        self.get_logger().info("on_configure() is called.")
        
        # Your exact publisher setup
        self._dbg_pub = self.create_publisher(Image, "dbg_image", 10)
        self._raw_pub = self.create_publisher(Image, "raw_image", 10)
        self._count_pub = self.create_publisher(Image, "dbg_counting", 10)
        self._bb_markers_pub = self.create_publisher(MarkerArray, "dgb_bb_markers", 10)
        self._kp_markers_pub = self.create_publisher(MarkerArray, "dgb_kp_markers", 10)
        self._counts_pub = self.create_publisher(ObjectCounts, "/yolo/objects/counts", 10)
        self._counts_mqtt_pub = self.create_publisher(String, "/vista/dashcam/debug_counter", 10)

        self.create_subscription(
            Image,
            "/image_raw",
            self.image_cb,
            10
        )
        self.create_subscription(
            DetectionArray,
            "/yolo/detections",
            self.detections_cb,
            10
        )
        return TransitionCallbackReturn.SUCCESS

    def resize_image(self, image: np.ndarray) -> np.ndarray:
        return cv2.resize(image, (self.target_width, self.target_height))

    def scale_detection(self, detection: Detection) -> Detection:
        detection.bbox.center.position.x *= self.scale_x
        detection.bbox.center.position.y *= self.scale_y
        detection.bbox.size_x *= self.scale_x
        detection.bbox.size_y *= self.scale_y
        return detection

    def draw_box(self, image: np.ndarray, detection: Detection, color: tuple) -> np.ndarray:
        x = detection.bbox.center.position.x
        y = detection.bbox.center.position.y
        w = detection.bbox.size_x
        h = detection.bbox.size_y

        x1 = int(x - w/2)
        y1 = int(y - h/2)
        x2 = int(x + w/2)
        y2 = int(y + h/2)

        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        cv2.putText(
            image,
            f"{detection.class_name} ({detection.id})",
            (x1, y1-10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            color,
            2
        )
        return image

    def publish_counts(self):
        counts = self.object_counter.get_counts()
        
        # ROS message
        msg = ObjectCounts()
        msg.header.stamp = self.get_clock().now().to_msg()
        msg.counts = [
            ObjectCount(class_name=class_name, count=count)
            for class_name, count in counts.items()
        ]
        self._counts_pub.publish(msg)
        
        # MQTT message
        mqtt_data = {
            "timestamp": msg.header.stamp.sec,
            "counts": counts
        }
        mqtt_msg = String()
        mqtt_msg.data = json.dumps(mqtt_data)
        self._counts_mqtt_pub.publish(mqtt_msg)

    def image_cb(self, msg: Image) -> None:
        cv_image = self.cv_bridge.imgmsg_to_cv2(msg)
        resized_image = self.resize_image(cv_image)
        
        # Calculate scale factors after resize
        self.scale_y = resized_image.shape[0] / self.target_height
        self.scale_x = resized_image.shape[1] / self.target_width
        
        # Publish raw image
        self._raw_pub.publish(self.cv_bridge.cv2_to_imgmsg(resized_image))

    def detections_cb(self, img_msg: Image, detection_msg: DetectionArray) -> None:
        current_time = self.get_clock().now().seconds_nanoseconds()[0]
        
        cv_image = self.cv_bridge.imgmsg_to_cv2(img_msg)
        resized_image = self.resize_image(cv_image)
        
        self.scale_y = resized_image.shape[0] / self.target_height
        self.scale_x = resized_image.shape[1] / self.target_width
        
        # Raw image
        self._raw_pub.publish(self.cv_bridge.cv2_to_imgmsg(resized_image))
        
        # Debug image (with bounding boxes)
        debug_image = resized_image.copy()
        for detection in detection_msg.detections:
            if detection.class_name not in self._class_to_color:
                self._class_to_color[detection.class_name] = (
                    random.randint(0, 255),
                    random.randint(0, 255),
                    random.randint(0, 255)
                )
            scaled_detection = self.scale_detection(detection)
            color = self._class_to_color[detection.class_name]
            debug_image = self.draw_box(debug_image, scaled_detection, color)
        self._dbg_pub.publish(self.cv_bridge.cv2_to_imgmsg(debug_image))
        
        # Counting image
        counting_image = resized_image.copy()
        self.object_counter.update_line_colors(current_time)
        counting_image = self.object_counter.draw_lines(counting_image)
        
        for detection in detection_msg.detections:
            scaled_detection = self.scale_detection(detection)
            if self.object_counter.check_line_crossings(scaled_detection, current_time):
                self.publish_counts()
            color = self._class_to_color[detection.class_name]
            counting_image = self.draw_box(counting_image, scaled_detection, color)
            
        self._count_pub.publish(self.cv_bridge.cv2_to_imgmsg(counting_image))


def main():
    rclpy.init()
    node = DebugNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()


if __name__ == "__main__":
    main()